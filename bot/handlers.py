import logging
from telegram import Update
from telegram.ext import ContextTypes

from core.spam_detector import SpamDetector
from core.punishment_manager import PunishmentManager
from core.whitelist import WhitelistManager
from utils.rate_limiter import RateLimiter

logger = logging.getLogger("telegram_bot")


class MessageHandler:
    """è¨Šæ¯è™•ç†å™¨"""

    def __init__(
        self,
        spam_detector: SpamDetector,
        punishment_manager: PunishmentManager,
        whitelist_manager: WhitelistManager,
        rate_limiter: RateLimiter,
        dry_run: bool = False
    ):
        self.spam_detector = spam_detector
        self.punishment = punishment_manager
        self.whitelist = whitelist_manager
        self.rate_limiter = rate_limiter
        self.dry_run = dry_run

        if self.dry_run:
            logger.warning("ğŸ”§ DRY RUN MODE ENABLED - No actions will be taken, only logging")

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        è™•ç†ç¾¤çµ„è¨Šæ¯

        æª¢æŸ¥æµç¨‹ï¼š
        1. æª¢æŸ¥æ˜¯å¦ç‚ºç™½åå–®ç”¨æˆ¶
        2. æª¢æŸ¥ API é…é¡
        3. ä½¿ç”¨ LLM æª¢æ¸¬åƒåœ¾è¨Šæ¯
        4. åŸ·è¡Œç›¸æ‡‰è™•ç½°
        """
        message = update.message

        # å¿½ç•¥éæ–‡å­—è¨Šæ¯
        if not message or not message.text:
            return

        # å¿½ç•¥æŒ‡ä»¤
        if message.text.startswith('/'):
            return

        user_id = message.from_user.id
        username = message.from_user.username or message.from_user.first_name
        message_text = message.text

        logger.debug(f"Processing message from user {user_id} ({username}): {message_text[:50]}...")

        # æª¢æŸ¥ç™½åå–®
        if self.whitelist.is_whitelisted(user_id):
            logger.debug(f"User {user_id} is whitelisted, skipping check")
            return

        # æª¢æŸ¥ API é…é¡
        can_call = await self.rate_limiter.can_call_api()
        if not can_call:
            remaining = await self.rate_limiter.get_remaining()
            logger.warning(
                f"Daily API limit reached, skipping detection for message from user {user_id}"
            )
            # é”åˆ°ä¸Šé™å¾Œä¸æª¢æ¸¬ï¼Œä½†è¨˜éŒ„æ—¥èªŒ
            if remaining == 0:
                # åªåœ¨ç¬¬ä¸€æ¬¡é”åˆ°ä¸Šé™æ™‚è¨˜éŒ„
                logger.error("âš ï¸ API daily limit reached! No more spam detection today.")
            return

        # ä½¿ç”¨ LLM æª¢æ¸¬åƒåœ¾è¨Šæ¯
        try:
            is_spam, score, reasoning = await self.spam_detector.check_message(message_text)
            await self.rate_limiter.increment()

            logger.info(
                f"Message checked: user={user_id}, username={username}, "
                f"score={score:.1f}, is_spam={is_spam}, reasoning={reasoning}"
            )

            # å¦‚æœæ˜¯åƒåœ¾è¨Šæ¯ï¼ŒåŸ·è¡Œè™•ç½°
            if is_spam:
                if self.dry_run:
                    # Dry Run æ¨¡å¼ï¼šåªè¨˜éŒ„ï¼Œä¸åŸ·è¡Œè™•ç½°
                    logger.warning(
                        f"ğŸ” [DRY RUN] Spam detected! user={user_id}, username={username}, "
                        f"score={score:.1f}, reasoning={reasoning}\n"
                        f"Message: {message_text}"
                    )
                else:
                    # æ­£å¸¸æ¨¡å¼ï¼šåŸ·è¡Œè™•ç½°
                    action = await self.punishment.handle_spam(
                        user_id=user_id,
                        username=username,
                        message=message,
                        llm_score=score
                    )
                    logger.warning(
                        f"ğŸš¨ Spam detected! user={user_id}, username={username}, "
                        f"score={score:.1f}, action={action}"
                    )

        except Exception as e:
            logger.error(
                f"Error processing message from user {user_id}: {e}",
                exc_info=True
            )
            # éŒ¯èª¤æ™‚ä¸è™•ç½°ç”¨æˆ¶ï¼Œé¿å…èª¤åˆ¤
